# MemGen Server Configuration for ARC
# Usage: python memgen_server.py --config configs/arc_server.yaml --port 8001

model:
  # Base LLM - same as training
  model_name: Qwen/Qwen2.5-7B-Instruct

  # Path to trained Weaver checkpoint (update after training)
  load_model_path: null  # e.g., outputs/arc_weaver_grpo/checkpoint-best

  # Augmentation settings
  max_prompt_aug_num: 1      # Single augmentation at prompt end
  max_inference_aug_num: 5   # Multiple augmentations during grid generation

  # Weaver configs (latent memory generator)
  weaver:
    model_name: Qwen/Qwen2.5-7B-Instruct
    prompt_latents_len: 8
    inference_latents_len: 8

    lora_config:
      r: 16
      lora_alpha: 32
      target_modules: ["q_proj", "v_proj"]
      lora_dropout: 0.0  # No dropout for inference
      bias: "none"
      task_type: "CAUSAL_LM"

  # Trigger configs (disabled - always inject)
  trigger:
    model_name: Qwen/Qwen2.5-7B-Instruct
    active: false

    lora_config:
      r: 16
      lora_alpha: 32
      target_modules: ["q_proj", "v_proj"]
      lora_dropout: 0.0
      bias: "none"
      task_type: "CAUSAL_LM"
